{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Database configuration â€” CHANGE these as per your setup\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': input(\"Enter MySQL username: \"),\n",
    "    'password': input(\"Enter MySQL password: \"),\n",
    "    'database': 'supermarket_db'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MySQL database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = mysql.connector.connect(**db_config)\n",
    "    if conn.is_connected():\n",
    "        print(\"Successfully connected to MySQL database.\")\n",
    "        cursor = conn.cursor()\n",
    "except Error as e:\n",
    "    print(f\"Error connecting to MySQL: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fetching and Preprocessing Data ---\n",
      "Loaded 1000 records.\n",
      "Target variable 'customer_type' encoded. Mapping: [('Member', np.int64(0)), ('Normal', np.int64(1))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_339503/2436555951.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Fetching and Preprocessing Data ---\")\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT invoice_id, city, gender, product_line, unit_price, quantity, total, customer_type FROM sales\n",
    "\"\"\"\n",
    "\n",
    "# Load data from MySQL into pandas DataFrame\n",
    "df = pd.read_sql(sql_query, conn)\n",
    "print(f\"Loaded {len(df)} records.\")\n",
    "\n",
    "# One-hot encoding categorical variables\n",
    "df_processed = pd.get_dummies(df, columns=['city', 'gender', 'product_line'], drop_first=True)\n",
    "\n",
    "# Label encode target variable\n",
    "le = LabelEncoder()\n",
    "df_processed['customer_type_encoded'] = le.fit_transform(df_processed['customer_type'])\n",
    "print(f\"Target variable 'customer_type' encoded. Mapping: {list(zip(le.classes_, le.transform(le.classes_)))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing data for training ---\n",
      "Train set size: 800 samples\n",
      "Test set size: 200 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing data for training ---\")\n",
    "\n",
    "features = [col for col in df_processed.columns if col not in ['invoice_id', 'customer_type', 'customer_type_encoded']]\n",
    "X = df_processed[features]\n",
    "y = df_processed['customer_type_encoded']\n",
    "\n",
    "# Split data 80/20 train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy on Test Data: 0.52\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Member       0.53      0.46      0.49       102\n",
      "      Normal       0.50      0.57      0.54        98\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.52      0.52      0.51       200\n",
      "weighted avg       0.52      0.52      0.51       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy on Test Data: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulating Predictions and Preparing for Storage ---\n",
      "Predictions on new data:\n",
      "  Invoice ID: 532-59-7201 -> Predicted Customer Type: Normal\n",
      "  Invoice ID: 701-69-8742 -> Predicted Customer Type: Normal\n",
      "  Invoice ID: 704-10-4056 -> Predicted Customer Type: Normal\n",
      "  Invoice ID: 635-28-5728 -> Predicted Customer Type: Normal\n",
      "  Invoice ID: 431-66-2305 -> Predicted Customer Type: Member\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Simulating Predictions and Preparing for Storage ---\")\n",
    "\n",
    "# Taking first 5 rows of test set as new data\n",
    "new_data_X = X_test.head(5)\n",
    "original_indices = new_data_X.index\n",
    "new_data_invoices = df.loc[original_indices, 'invoice_id']\n",
    "\n",
    "# Predict on new data\n",
    "new_predictions_encoded = model.predict(new_data_X)\n",
    "new_predictions_labels = le.inverse_transform(new_predictions_encoded)\n",
    "\n",
    "print(\"Predictions on new data:\")\n",
    "for inv, pred in zip(new_data_invoices, new_predictions_labels):\n",
    "    print(f\"  Invoice ID: {inv} -> Predicted Customer Type: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'sales_predictions' table checked/created in MySQL.\n",
      "5 predictions inserted into sales_predictions table.\n"
     ]
    }
   ],
   "source": [
    "# Create the predictions table if it doesn't exist\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sales_predictions (\n",
    "    prediction_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    invoice_id VARCHAR(20) NOT NULL,\n",
    "    predicted_customer_type VARCHAR(20),\n",
    "    prediction_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY (invoice_id) REFERENCES sales(invoice_id)\n",
    ")\n",
    "\"\"\")\n",
    "print(\"\\n'sales_predictions' table checked/created in MySQL.\")\n",
    "\n",
    "# Insert predictions into the table\n",
    "insert_query = \"INSERT INTO sales_predictions (invoice_id, predicted_customer_type) VALUES (%s, %s)\"\n",
    "predictions_to_store = list(zip(new_data_invoices, new_predictions_labels))\n",
    "cursor.executemany(insert_query, predictions_to_store)\n",
    "conn.commit()\n",
    "print(f\"{cursor.rowcount} predictions inserted into sales_predictions table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_339503/1945055905.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_predictions = pd.read_sql(\"SELECT * FROM sales_predictions ORDER BY prediction_timestamp DESC\", conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>predicted_customer_type</th>\n",
       "      <th>prediction_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>532-59-7201</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2025-07-28 13:40:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>701-69-8742</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2025-07-28 13:40:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>704-10-4056</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2025-07-28 13:40:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>635-28-5728</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2025-07-28 13:40:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>431-66-2305</td>\n",
       "      <td>Member</td>\n",
       "      <td>2025-07-28 13:40:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_id   invoice_id predicted_customer_type prediction_timestamp\n",
       "0              1  532-59-7201                  Normal  2025-07-28 13:40:50\n",
       "1              2  701-69-8742                  Normal  2025-07-28 13:40:50\n",
       "2              3  704-10-4056                  Normal  2025-07-28 13:40:50\n",
       "3              4  635-28-5728                  Normal  2025-07-28 13:40:50\n",
       "4              5  431-66-2305                  Member  2025-07-28 13:40:50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use pandas to read the data into a DataFrame for easy viewing\n",
    "df_predictions = pd.read_sql(\"SELECT * FROM sales_predictions ORDER BY prediction_timestamp DESC\", conn)\n",
    "\n",
    "if df_predictions.empty:\n",
    "    print(\"No prediction records found in 'sales_predictions' table.\")\n",
    "else:\n",
    "    display(df_predictions)  # If using Jupyter notebook, display the table nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 rows from 'sales_predictions' table.\n",
      "Table 'sales_predictions' successfully saved as 'sales_predictions.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_339503/2701955691.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql_query, conn)\n"
     ]
    }
   ],
   "source": [
    "table_name = \"sales_predictions\"\n",
    "# Query entire table\n",
    "sql_query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Load data into pandas DataFrame\n",
    "df = pd.read_sql(sql_query, conn)\n",
    "print(f\"Loaded {len(df)} rows from '{table_name}' table.\")\n",
    "\n",
    "# Save to CSV\n",
    "output_file = f\"{table_name}.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Table '{table_name}' successfully saved as '{output_file}'.\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
